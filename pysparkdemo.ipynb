{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960be23-4b8c-458d-bdd1-c74ab5851a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"pysparkdemo\") \\\n",
    ".getOrCreate()\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1427ca-f305-4b7b-8a5f-5428b20a094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\", \"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321f2f7-c0db-48ab-80f7-19bef179b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a45002-acc6-41b3-8745-70f1906825de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65347e41-5f67-4cb9-91f7-09e6302db7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490c5ed-e758-4a0c-978a-b9417107df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ff0e0-de02-4ee3-ab0a-64e0268ac796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"firstname\",\"lastname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178c196-e21b-44a0-a4c7-dba1af25e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\"),col(\"lastname\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48bdeb7-d3f1-42b5-86b1-23be980eeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select All columns from List\n",
    "df.select(*columns).show()\n",
    "# Select All columns\n",
    "df.select([col for col in df.columns]).show()\n",
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc100a1d-25ed-4074-89e7-803757c828a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.columns[:3]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59a52c-5960-4a8e-b3bf-a0596ca9f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.columns[2:4]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45556e6-2bfe-41b5-ad4f-1e6dfb6dbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with nested columns\n",
    "data = [\n",
    "        ((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
    "        ]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType  \n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "\n",
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False) # shows all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b5359-bb65-4201-aa98-4acbde45a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show() # shows all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c7cf4-e1ee-4b84-a5b6-f81e641982b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\"name\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a88d23-05cc-428a-b986-6691e8d1d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\"name.firstname\", \"name.lastname\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bad4f-56a0-4bbb-910f-9c3301dad9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "# Create data\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "\n",
    "# Create schema        \n",
    "schema = StructType([\n",
    "     StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])\n",
    "\n",
    "# Create dataframe\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2616d-2da1-4a57-94bf-ba8be5790923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.state==\"OH\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb77eb-f62d-4f4d-bff7-0172b5c12dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.state!=\"OH\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a4113-f15f-40f6-8b11-0b5e318f1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(col(\"state\") == \"OH\") \\\n",
    "    .show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c6177-1e1a-4ea8-abf0-647b448da350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL Expression\n",
    "df.filter(\"gender == 'M'\").show()\n",
    "# For not equal\n",
    "df.filter(\"gender != 'M'\").show()\n",
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c6808-36f5-4b2a-ae4f-fecf02f92dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter multiple conditions\n",
    "df.filter( (df.state  == \"OH\") & (df.gender  == \"M\") ) \\\n",
    "    .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419bdc3-7530-4fac-92ce-87b27d2abefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter using OR operator\n",
    "df.filter( (df.state  == \"OH\") | (df.gender  == \"M\") ) \\\n",
    "    .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9356d73-5dc4-4a21-9f70-f1afbda8e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "li=[\"OH\",\"CA\",\"DE\"]\n",
    "df.filter(df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf9226-fa4e-4324-97bb-3eca19725970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.state.startswith(\"N\")).show()\n",
    "df.filter(df.state.endswith(\"H\")).show()\n",
    "df.filter(df.state.contains(\"H\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041651e9-527b-4eed-9028-42b50de3192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a885e-b863-43cb-b095-c573838910bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.name.lastname.like(\"%il%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f47fc-ba9a-4d7b-a0ec-da83eb0c9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.filter(array_contains(df.languages,\"Java\")) \\\n",
    "    .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50945910-6c6c-4c12-aa5f-47cf4ae40f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "# Create SparkSession\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141d55b-4b31-49f9-a3dd-ee930936064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(\"department\",\"state\").show(truncate=False)\n",
    "df.sort(col(\"department\"),col(\"state\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc7828-174a-4f00-8625-e521aa07349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(\"department\",\"state\").show(truncate=False)\n",
    "df.orderBy(col(\"department\"),col(\"state\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de8763-fff2-40a1-88a3-433cec5c88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(df.department.asc(),df.state.desc()).show(truncate=False)\n",
    "df.sort(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)\n",
    "df.orderBy(col(\"department\").asc(),col(\"state\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de57432-9a23-4366-b782-92cac854751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select employee_name,department,state,salary,age,bonus from EMP ORDER BY department asc\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f7f30-6f81-419f-a631-e622ebd9028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f0ac4-3869-4761-baca-d2315e4a450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\").count().show()\n",
    "df.groupBy(\"department\").min(\"salary\").show()\n",
    "df.groupBy(\"department\").max(\"salary\").show()\n",
    "df.groupBy(\"department\").mean( \"salary\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b36b74-6402-4712-9eb5-60503f18b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\",\"state\") \\\n",
    "    .sum(\"salary\",\"bonus\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ef996-33e8-4b29-b1c6-1fe4dff26bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max\n",
    "\n",
    "# Running more aggregations\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd36e2-2ed7-4414-be95-1465cbdbed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max\n",
    "\n",
    "# Using filter on aggregate data\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a7ec8-bb79-49b3-8061-9b53236108f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register DataFrame as a temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# Using SQL Query\n",
    "sql_string = \"\"\"SELECT department,\n",
    "       SUM(salary) AS sum_salary,\n",
    "       AVG(salary) AS avg_salary,\n",
    "       SUM(bonus) AS sum_bonus,\n",
    "       MAX(bonus) AS max_bonus\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "HAVING SUM(bonus) >= 50000\"\"\"\n",
    "\n",
    "# Execute SQL query against the temporary view\n",
    "df2 = spark.sql(sql_string)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6485e-db07-4473-96c5-0880b5544807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
